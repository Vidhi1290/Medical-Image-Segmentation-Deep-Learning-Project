{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "import torch\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "from collections import OrderedDict\n",
    "from albumentations.augmentations import transforms\n",
    "from sklearn.model_selection import train_test_split\n",
    "from albumentations.core.composition import Compose, OneOf\n",
    "\n",
    "# from train import train, validate\n",
    "# from source.network import UNetPP\n",
    "# from source.dataset import DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch.utils.data\n",
    "\n",
    "\n",
    "class DataSet(torch.utils.data.Dataset):\n",
    "    def __init__(self, img_ids, img_dir, mask_dir, img_ext, mask_ext, transform=None):\n",
    "        self.img_ids = img_ids\n",
    "        self.img_dir = img_dir\n",
    "        self.mask_dir = mask_dir\n",
    "        self.img_ext = img_ext\n",
    "        self.mask_ext = mask_ext\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_id = self.img_ids[idx]\n",
    "\n",
    "        img = cv2.imread(os.path.join(self.img_dir, img_id + self.img_ext))\n",
    "\n",
    "        mask = []\n",
    "        mask.append(cv2.imread(os.path.join(self.mask_dir,\n",
    "                                            img_id + self.mask_ext), cv2.IMREAD_GRAYSCALE)[..., None])\n",
    "        mask = np.dstack(mask)\n",
    "\n",
    "        if self.transform is not None:\n",
    "            augmented = self.transform(image=img, mask=mask)\n",
    "            img = augmented['image']\n",
    "            mask = augmented['mask']\n",
    "\n",
    "        img = img.astype('float32') / 255\n",
    "        img = img.transpose(2, 0, 1)\n",
    "        mask = mask.astype('float32') / 255\n",
    "        mask = mask.transpose(2, 0, 1)\n",
    "\n",
    "        return img, mask, {'img_id': img_id}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "\n",
    "class VGGBlock(nn.Module):\n",
    "    def __init__(self, in_channels, middle_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv1 = nn.Conv2d(in_channels, middle_channels, 3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(middle_channels)\n",
    "        self.conv2 = nn.Conv2d(middle_channels, out_channels, 3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class UNetPP(nn.Module):\n",
    "    def __init__(self, num_classes, input_channels=3, deep_supervision=False, **kwargs):\n",
    "        super().__init__()\n",
    "\n",
    "        nb_filter = [32, 64, 128, 256, 512]\n",
    "\n",
    "        self.deep_supervision = deep_supervision\n",
    "\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "\n",
    "        self.conv0_0 = VGGBlock(input_channels, nb_filter[0], nb_filter[0])\n",
    "        self.conv1_0 = VGGBlock(nb_filter[0], nb_filter[1], nb_filter[1])\n",
    "        self.conv2_0 = VGGBlock(nb_filter[1], nb_filter[2], nb_filter[2])\n",
    "        self.conv3_0 = VGGBlock(nb_filter[2], nb_filter[3], nb_filter[3])\n",
    "        self.conv4_0 = VGGBlock(nb_filter[3], nb_filter[4], nb_filter[4])\n",
    "\n",
    "        self.conv0_1 = VGGBlock(nb_filter[0]+nb_filter[1], nb_filter[0], nb_filter[0])\n",
    "        self.conv1_1 = VGGBlock(nb_filter[1]+nb_filter[2], nb_filter[1], nb_filter[1])\n",
    "        self.conv2_1 = VGGBlock(nb_filter[2]+nb_filter[3], nb_filter[2], nb_filter[2])\n",
    "        self.conv3_1 = VGGBlock(nb_filter[3]+nb_filter[4], nb_filter[3], nb_filter[3])\n",
    "\n",
    "        self.conv0_2 = VGGBlock(nb_filter[0]*2+nb_filter[1], nb_filter[0], nb_filter[0])\n",
    "        self.conv1_2 = VGGBlock(nb_filter[1]*2+nb_filter[2], nb_filter[1], nb_filter[1])\n",
    "        self.conv2_2 = VGGBlock(nb_filter[2]*2+nb_filter[3], nb_filter[2], nb_filter[2])\n",
    "\n",
    "        self.conv0_3 = VGGBlock(nb_filter[0]*3+nb_filter[1], nb_filter[0], nb_filter[0])\n",
    "        self.conv1_3 = VGGBlock(nb_filter[1]*3+nb_filter[2], nb_filter[1], nb_filter[1])\n",
    "\n",
    "        self.conv0_4 = VGGBlock(nb_filter[0]*4+nb_filter[1], nb_filter[0], nb_filter[0])\n",
    "\n",
    "        if self.deep_supervision:\n",
    "            self.final1 = nn.Conv2d(nb_filter[0], num_classes, kernel_size=1)\n",
    "            self.final2 = nn.Conv2d(nb_filter[0], num_classes, kernel_size=1)\n",
    "            self.final3 = nn.Conv2d(nb_filter[0], num_classes, kernel_size=1)\n",
    "            self.final4 = nn.Conv2d(nb_filter[0], num_classes, kernel_size=1)\n",
    "        else:\n",
    "            self.final = nn.Conv2d(nb_filter[0], num_classes, kernel_size=1)\n",
    "\n",
    "\n",
    "    def forward(self, input):\n",
    "        x0_0 = self.conv0_0(input)\n",
    "        x1_0 = self.conv1_0(self.pool(x0_0))\n",
    "        x0_1 = self.conv0_1(torch.cat([x0_0, self.up(x1_0)], 1))\n",
    "\n",
    "        x2_0 = self.conv2_0(self.pool(x1_0))\n",
    "        x1_1 = self.conv1_1(torch.cat([x1_0, self.up(x2_0)], 1))\n",
    "        x0_2 = self.conv0_2(torch.cat([x0_0, x0_1, self.up(x1_1)], 1))\n",
    "\n",
    "        x3_0 = self.conv3_0(self.pool(x2_0))\n",
    "        x2_1 = self.conv2_1(torch.cat([x2_0, self.up(x3_0)], 1))\n",
    "        x1_2 = self.conv1_2(torch.cat([x1_0, x1_1, self.up(x2_1)], 1))\n",
    "        x0_3 = self.conv0_3(torch.cat([x0_0, x0_1, x0_2, self.up(x1_2)], 1))\n",
    "\n",
    "        x4_0 = self.conv4_0(self.pool(x3_0))\n",
    "        x3_1 = self.conv3_1(torch.cat([x3_0, self.up(x4_0)], 1))\n",
    "        x2_2 = self.conv2_2(torch.cat([x2_0, x2_1, self.up(x3_1)], 1))\n",
    "        x1_3 = self.conv1_3(torch.cat([x1_0, x1_1, x1_2, self.up(x2_2)], 1))\n",
    "        x0_4 = self.conv0_4(torch.cat([x0_0, x0_1, x0_2, x0_3, self.up(x1_3)], 1))\n",
    "\n",
    "        if self.deep_supervision:\n",
    "            output1 = self.final1(x0_1)\n",
    "            output2 = self.final2(x0_2)\n",
    "            output3 = self.final3(x0_3)\n",
    "            output4 = self.final4(x0_4)\n",
    "            return [output1, output2, output3, output4]\n",
    "\n",
    "        else:\n",
    "            output = self.final(x0_4)\n",
    "            return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "\n",
    "def iou_score(output, target):\n",
    "    smooth = 1e-5\n",
    "\n",
    "    if torch.is_tensor(output):\n",
    "        output = torch.sigmoid(output).data.cpu().numpy()\n",
    "    if torch.is_tensor(target):\n",
    "        target = target.data.cpu().numpy()\n",
    "    output_ = output > 0.5\n",
    "    target_ = target > 0.5\n",
    "    intersection = (output_ & target_).sum()\n",
    "    union = (output_ | target_).sum()\n",
    "\n",
    "    return (intersection + smooth) / (union + smooth)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "import torch\n",
    "import pandas as pd\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "from collections import OrderedDict\n",
    "from source.utils import iou_score, AverageMeter\n",
    "from albumentations import Resize\n",
    "from albumentations.augmentations import transforms\n",
    "from sklearn.model_selection import train_test_split\n",
    "from albumentations.core.composition import Compose, OneOf\n",
    "from albumentations.augmentations.geometric.rotate import RandomRotate90\n",
    "from source.network import UNetPP\n",
    "from source.dataset import DataSet\n",
    "\n",
    "\n",
    "def train(deep_sup, train_loader, model, criterion, optimizer):\n",
    "    avg_meters = {'loss': AverageMeter(),\n",
    "                  'iou': AverageMeter()}\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    pbar = tqdm(total=len(train_loader))\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    for input, target, _ in train_loader:\n",
    "        input = input.to(device)\n",
    "        target = target.to(device)\n",
    "\n",
    "        # compute output\n",
    "        if deep_sup:\n",
    "            outputs = model(input)\n",
    "            loss = 0\n",
    "            for output in outputs:\n",
    "                loss += criterion(output, target)\n",
    "            loss /= len(outputs)\n",
    "            iou = iou_score(outputs[-1], target)\n",
    "        else:\n",
    "            output = model(input)\n",
    "            loss = criterion(output, target)\n",
    "            iou = iou_score(output, target)\n",
    "\n",
    "        # compute gradient and do optimizing step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        avg_meters['loss'].update(loss.item(), input.size(0))\n",
    "        avg_meters['iou'].update(iou, input.size(0))\n",
    "\n",
    "        postfix = OrderedDict([\n",
    "            ('loss', avg_meters['loss'].avg),\n",
    "            ('iou', avg_meters['iou'].avg),\n",
    "        ])\n",
    "        pbar.set_postfix(postfix)\n",
    "        pbar.update(1)\n",
    "    pbar.close()\n",
    "\n",
    "    return OrderedDict([('loss', avg_meters['loss'].avg),\n",
    "                        ('iou', avg_meters['iou'].avg)])\n",
    "\n",
    "\n",
    "def validate(deep_sup, val_loader, model, criterion):\n",
    "    avg_meters = {'loss': AverageMeter(),\n",
    "                  'iou': AverageMeter()}\n",
    "\n",
    "    # switch to evaluate mode\n",
    "    model.eval()\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        pbar = tqdm(total=len(val_loader))\n",
    "        for input, target, _ in val_loader:\n",
    "            input = input.to(device)\n",
    "            target = target.to(device)\n",
    "\n",
    "            # compute output\n",
    "            if deep_sup:\n",
    "                outputs = model(input)\n",
    "                loss = 0\n",
    "                for output in outputs:\n",
    "                    loss += criterion(output, target)\n",
    "                loss /= len(outputs)\n",
    "                iou = iou_score(outputs[-1], target)\n",
    "            else:\n",
    "                output = model(input)\n",
    "                loss = criterion(output, target)\n",
    "                iou = iou_score(output, target)\n",
    "\n",
    "            avg_meters['loss'].update(loss.item(), input.size(0))\n",
    "            avg_meters['iou'].update(iou, input.size(0))\n",
    "\n",
    "            postfix = OrderedDict([\n",
    "                ('loss', avg_meters['loss'].avg),\n",
    "                ('iou', avg_meters['iou'].avg),\n",
    "            ])\n",
    "            pbar.set_postfix(postfix)\n",
    "            pbar.update(1)\n",
    "        pbar.close()\n",
    "\n",
    "    return OrderedDict([('loss', avg_meters['loss'].avg),\n",
    "                        ('iou', avg_meters['iou'].avg)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import yaml\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from source.network import UNetPP\n",
    "from argparse import ArgumentParser\n",
    "from albumentations.augmentations import transforms\n",
    "from albumentations.core.composition import Compose\n",
    "\n",
    "\n",
    "val_transform = Compose([\n",
    "    transforms.Resize(256, 256),\n",
    "    transforms.Normalize(),\n",
    "])\n",
    "\n",
    "\n",
    "def image_loader(image_name):\n",
    "    img = cv2.imread(image_name)\n",
    "    img = val_transform(image=img)[\"image\"]\n",
    "    img = img.astype('float32') / 255\n",
    "    img = img.transpose(2, 0, 1)\n",
    "\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"config.yaml\") as f:\n",
    "    config = yaml.load(f)\n",
    "\n",
    "extn = config[\"extn\"]\n",
    "epochs = config[\"epochs\"]\n",
    "log_path = config[\"log_path\"]\n",
    "mask_path = config[\"mask_path\"]\n",
    "image_path = config[\"image_path\"]\n",
    "model_path = config[\"model_path\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create log file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log = OrderedDict([\n",
    "    ('epoch', []),\n",
    "    ('loss', []),\n",
    "    ('iou', []),\n",
    "    ('val_loss', []),\n",
    "    ('val_iou', []),\n",
    "])\n",
    "\n",
    "best_iou = 0\n",
    "trigger = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split images into train and validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extn_ = f\"*{extn}\"\n",
    "img_ids = glob(os.path.join(image_path, extn_))\n",
    "img_ids = [os.path.splitext(os.path.basename(p))[0] for p in img_ids]\n",
    "train_img_ids, val_img_ids = train_test_split(img_ids, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define data transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = Compose([\n",
    "    transforms.RandomRotate90(),\n",
    "    transforms.Flip(),\n",
    "    OneOf([\n",
    "        transforms.HueSaturationValue(),\n",
    "        transforms.RandomBrightness(),\n",
    "        transforms.RandomContrast(),\n",
    "    ], p=1),\n",
    "    transforms.Resize(256, 256),\n",
    "    transforms.Normalize(),\n",
    "])\n",
    "\n",
    "val_transform = Compose([\n",
    "    transforms.Resize(256, 256),\n",
    "    transforms.Normalize(),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create train and validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = DataSet(\n",
    "    img_ids=train_img_ids,\n",
    "    img_dir=image_path,\n",
    "    mask_dir=mask_path,\n",
    "    img_ext=extn,\n",
    "    mask_ext=extn,\n",
    "    transform=train_transform)\n",
    "\n",
    "val_dataset = DataSet(\n",
    "    img_ids=val_img_ids,\n",
    "    img_dir=image_path,\n",
    "    mask_dir=mask_path,\n",
    "    img_ext=extn,\n",
    "    mask_ext=extn,\n",
    "    transform=val_transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create train and validation data loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=16,\n",
    "    shuffle=True,\n",
    "    drop_last=True)\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=16,\n",
    "    shuffle=False,\n",
    "    drop_last=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the model object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model object\n",
    "model = UNetPP(1, 3, True)\n",
    "\n",
    "# Port model to GPU if it is available\n",
    "if torch.cuda.is_available():\n",
    "    model.cuda()\n",
    "    \n",
    "# Define Loss Function\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "params = filter(lambda p: p.requires_grad, model.parameters())\n",
    "\n",
    "# Define Optimizer\n",
    "optimizer = optim.Adam(params, lr=1e-3, weight_decay=1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the train loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(epochs):\n",
    "    print(f'Epoch [{epoch}/{epochs}]')\n",
    "\n",
    "    # train for one epoch\n",
    "    train_log = train(True, train_loader, model, criterion, optimizer)\n",
    "    # evaluate on validation set\n",
    "    val_log = validate(True, val_loader, model, criterion)\n",
    "\n",
    "    print('loss %.4f - iou %.4f - val_loss %.4f - val_iou %.4f'\n",
    "              % (train_log['loss'], train_log['iou'], val_log['loss'], val_log['iou']))\n",
    "\n",
    "    log['epoch'].append(epoch)\n",
    "    log['loss'].append(train_log['loss'])\n",
    "    log['iou'].append(train_log['iou'])  \n",
    "    log['val_loss'].append(val_log['loss'])\n",
    "    log['val_iou'].append(val_log['iou'])\n",
    "\n",
    "    pd.DataFrame(log).to_csv(log_path, index=False)\n",
    "\n",
    "    trigger += 1\n",
    "\n",
    "    if val_log['iou'] > best_iou:\n",
    "        torch.save(model.state_dict(), model_path)\n",
    "        best_iou = val_log['iou']\n",
    "        print(\"=> saved best model\")\n",
    "        trigger = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import yaml\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from predict import image_loader\n",
    "from source.network import UNetPP\n",
    "from argparse import ArgumentParser\n",
    "from albumentations.augmentations import transforms\n",
    "from albumentations.core.composition import Compose\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create validation transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_transform = Compose([\n",
    "    transforms.Resize(256, 256),\n",
    "    transforms.Normalize(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"config.yaml\") as f:\n",
    "    config = yaml.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_width = config[\"im_width\"]\n",
    "im_height = config[\"im_height\"]\n",
    "model_path = config[\"model_path\"]\n",
    "output_path = config[\"output_path\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model object\n",
    "model = UNetPP(1, 3, True)\n",
    "\n",
    "# Load pre-trained weights\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "\n",
    "# Port the model to GPU if it is available\n",
    "if torch.cuda.is_available():\n",
    "    model.cuda()\n",
    "    \n",
    "# Set model mode to evaluation\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the test image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_img = \"input/PNG/Original/115.png\"\n",
    "image = image_loader(test_img)\n",
    "\n",
    "# Convert the image to a batch of 1 image\n",
    "image = np.expand_dims(image,0)\n",
    "\n",
    "# Convert numpy array to torch tensor\n",
    "image = torch.from_numpy(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Port the image to GPU if it is available\n",
    "if torch.cuda.is_available():\n",
    "    image = image.to(device=\"cuda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = model(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = mask[-1]\n",
    "\n",
    "# Convert torch tensor to numpy array\n",
    "mask = mask.detach().cpu().numpy()\n",
    "\n",
    "# Convert output to a 2-d array\n",
    "mask = np.squeeze(np.squeeze(mask, axis=0), axis=0)\n",
    "\n",
    "# Convert output to binary based on threshold\n",
    "mask[mask > -2.5] = 255\n",
    "mask[mask <= -2.5] = 0\n",
    "\n",
    "# Resize the ouptut image to input image size\n",
    "mask = cv2.resize(mask, (im_width, im_height))\n",
    "\n",
    "# Plot the generated mask\n",
    "plt.imshow(mask, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read and plot the ground truth mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_mask = \"input/PNG/Ground Truth/115.png\"\n",
    "am = plt.imread(actual_mask)\n",
    "plt.imshow(am, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "UNET++.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}